<canvas id="canvas" width="320" height="240" style="display: none;"></canvas>

<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
<script>
    async function initCamera() {
        // Initialize the camera and return a video element
        const video = document.createElement('video');
        video.width = 320;
        video.height = 320;
        document.body.appendChild(video);

        const stream = await navigator.mediaDevices.getUserMedia({ video: true });
        video.srcObject = stream;
        await new Promise((resolve) => {
            video.onloadedmetadata = () => {
                resolve();
            };
        });
        video.play();
        return video;
    }

    function createModel() {
        const model = tf.sequential();
        model.add(tf.layers.conv2d({
            inputShape: [320, 320, 3],
            filters: 32,
            kernelSize: 3,
            activation: 'relu'
        }));
        model.add(tf.layers.maxPooling2d({ poolSize: [2, 2] }));
        model.add(tf.layers.flatten());
        model.add(tf.layers.dense({ units: 128, activation: 'relu' }));
        model.add(tf.layers.dense({ units: 3, activation: 'softmax' }));

        model.compile({
            optimizer: 'adam',
            loss: 'categoricalCrossentropy',
            metrics: ['accuracy']
        });

        return model;
    }

    async function run() {
        const video = await initCamera();
        const model = createModel();

        setInterval(async () => {
            const tensor = tf.browser.fromPixels(video).resizeNearestNeighbor([320, 320]).toFloat().div(tf.scalar(255)).expandDims();
            const output = model.predict(tensor);

            await model.fit(tensor, output, {
                epochs: 1
            });

            // Generowanie dźwięku na podstawie obrazu
            generateSoundFromImage(output);
        }, 1000); // Co sekundę generuj dźwięk na podstawie obrazu
    }

    function generateSoundFromImage(tensor) {
        // Prosta transformacja obrazu na dźwięk - użyjemy częstotliwości zależnych od wartości w tensorze
        const frequency = tensor.mean().arraySync() * 1000 + 200;
        playSound(frequency);
    }

    function playSound(frequency) {
        const audioContext = new (window.AudioContext || window.webkitAudioContext)();
        const oscillator = audioContext.createOscillator();
        oscillator.type = 'sine';
        oscillator.frequency.setValueAtTime(frequency, audioContext.currentTime);
        oscillator.connect(audioContext.destination);
        oscillator.start();
        oscillator.stop(audioContext.currentTime + 1);  // Dźwięk trwający 1 sekundę
    }

    run().catch((err) => {
        console.error("Błąd kamery:", err);
    });
</script>